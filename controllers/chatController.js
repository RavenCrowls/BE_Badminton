require('dotenv').config();
const { supabase } = require('../supabase');
const { SupabaseVectorStore } = require('@langchain/community/vectorstores/supabase');
const { GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI } = require('@langchain/google-genai');
const { StringOutputParser } = require('@langchain/core/output_parsers');
const { ChatPromptTemplate } = require("@langchain/core/prompts");
const { RunnableSequence } = require("@langchain/core/runnables");
const { TaskType } = require("@google/generative-ai"); // Import tr·ª±c ti·∫øp

// 1. C·∫§U H√åNH EMBEDDING (QUERY)
const embeddings = new GoogleGenerativeAIEmbeddings({
  apiKey: process.env.GOOGLE_API_KEY,
  model: 'text-embedding-004', 
  taskType: TaskType.RETRIEVAL_QUERY, // <--- B·∫ÆT BU·ªòC KH√ÅC V·ªöI INGEST
});

// 2. MODEL CHAT
const chatModel = new ChatGoogleGenerativeAI({
  apiKey: process.env.GOOGLE_API_KEY,
  model: 'gemini-2.0-flash', 
  temperature: 0.3,
});

async function handleChat(req, res) {
  try {
    const { question } = req.body;
    if (!question) return res.status(400).json({ error: 'Vui l√≤ng nh·∫≠p c√¢u h·ªèi!' });

    console.log(`\nüí¨ C√¢u h·ªèi: "${question}"`);

    // 3. T√åM KI·∫æM
    const vectorStore = new SupabaseVectorStore(embeddings, {
      client: supabase,
      tableName: 'documents',
      queryName: 'match_documents'
    });

    // Debug: In ra vector c·ªßa c√¢u h·ªèi ƒë·ªÉ ch·∫Øc ch·∫Øn n√≥ ho·∫°t ƒë·ªông
    // const qVector = await embeddings.embedQuery(question);
    // console.log("Vector c√¢u h·ªèi (length):", qVector.length);

    const docs = await vectorStore.similaritySearch(question, 5);
    console.log(`üîé T√¨m th·∫•y: ${docs.length} ƒëo·∫°n.`);

    // Log n·ªôi dung t√¨m th·∫•y ƒë·ªÉ debug
    if (docs.length > 0) {
        console.log("üìù N·ªôi dung ƒëo·∫°n ƒë·∫ßu ti√™n t√¨m th·∫•y:", docs[0].pageContent.substring(0, 100) + "...");
    } else {
        console.log("‚ö†Ô∏è KH√îNG T√åM TH·∫§Y G√å!");
        return res.json({ answer: "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin trong t√†i li·ªáu." });
    }

    // 4. TR·∫¢ L·ªúI
    const prompt = ChatPromptTemplate.fromTemplate(`
      B·∫°n l√† tr·ª£ l√Ω Shop C·∫ßu L√¥ng. D·ª±a v√†o th√¥ng tin sau ƒë·ªÉ tr·∫£ l·ªùi:
      <context>{context}</context>
      C√¢u h·ªèi: {question}
    `);

    const chain = RunnableSequence.from([
      {
        context: () => docs.map(d => d.pageContent).join('\n\n'),
        question: () => question,
      },
      prompt,
      chatModel,
      new StringOutputParser(),
    ]);

    const answer = await chain.invoke({ question });
    console.log("ü§ñ AI:", answer);
    
    return res.json({ answer });

  } catch (err) {
    console.error('‚ùå L·ªói:', err);
    return res.status(500).json({ error: err.message });
  }
}

module.exports = { handleChat };